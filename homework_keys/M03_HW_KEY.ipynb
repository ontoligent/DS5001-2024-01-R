{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ai-gvPnADykO",
    "tags": []
   },
   "source": [
    "# Metadata\n",
    "\n",
    "```yaml\n",
    "Course: DS 5001 \n",
    "Module: 03: Homework KEY\n",
    "Topics: Inferring and Interpreting Language Models \n",
    "Author: R.C. Alvarado\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Use the the following libraries and source text to answer the questions in this assessment. \n",
    "  * `pg42324.txt`\n",
    "  * `textimporter.py`\n",
    "\n",
    "Follow this pattern:\n",
    "* Create a new notebook for your work.\n",
    "* Parse the _Frankenstein_ text to generate TOKENS and VOCAB tables.\n",
    "* Create a list of sentences from the TOKENS table and a list of terms from the VOCAB table. \n",
    "* Generate ngram type tables and models, going up to the trigram level.\n",
    "* Write the code to answer the following questions:\n",
    "  1. List six words that precede the word \"monster,\" excluding stop words (and sentence boundary markers). Stop words include 'a', 'an', 'the', 'this', 'that', etc. Hint: use the `df.query()` method.  \n",
    "  2. List the following sentences in ascending order of bigram perpexity according to the language model generated from the text:\n",
    "    ```\n",
    "    The monster is on the ice.\n",
    "    Flowers are happy things.\n",
    "    I have never seen the aurora borealis.\n",
    "    He never knew the love of a family.\n",
    "    ```\n",
    "  3. Using the bigram model represented as a matrix, explore the relationship between bigram pairs using the following lists. Hint: use the `.unstack()` method on the feature `n` and then use `.loc[]` to select the first list from the index, and the second list from the columns.\n",
    "     1. `['he','she']` to select the indices.\n",
    "     2. `['said','heard']` to select the columns.\n",
    "  4. Generate 20 sentences using the `.generate_text()` method from the `langmod.NgramLanguageModel` class.\n",
    "  5. Compute the redundancy $R$ for each of the n-gram models using the MLE of the joint probability of each ngram type. In other words, for each model, just use the `.mle` feature as $p$ in computing $H = \\sum p(ng) \\log_2(1/p(ng))$. Does $R$ increase, decrease, or remain the same as the choice of n-gram increases in length? Hint: Remember that $R = 1 - \\frac{H}{H_{max}}$, where $H$ is the actual entropy of the model and $H_{max}$ is its maximum entropy. \n",
    "  \n",
    "**Hints for Q5:**\n",
    "\n",
    "- If `mle` is not a feature in your models, just use `p` for the unigram model and compute `p` for the other two models by dividing `n` by the sum of `n`, i.e. \n",
    "\n",
    "```python\n",
    "M[1]['p'] = M[1].n /  M[1].n.sum()\n",
    "M[2]['p'] = M[2].n /  M[2].n.sum()\n",
    "``` \n",
    "- N is computed as the number of all possible combinations for each ngram. So, for the bigram model N is the number of unigrams (i.e. the vocabulary size plus the sentence boundary signs) squared, and for the trigram model the value is cubed, i.e.\n",
    "\n",
    "```python\n",
    "N = len(M[0].index)**{i+1}\n",
    "```\n",
    "\n",
    "\n",
    "**Other Hints**:\n",
    "* You may use the libraries or cut-and-paste code from the relevant notebooks.\n",
    "* Use the `M03_06_NGramLanguageModels.ipynb` for code patterns.\n",
    "* The story begins with the Preface.\n",
    "* Even though they are not called \"chapters,\" treat the Preface and Letters as chapters.\n",
    "* You don't have to use the \"START OF PROJECT GUTENBERG ...\", etc., to clip the text. Find the lines where you think the text actually begins and ends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "local_lib = config['DEFAULT']['local_lib']\n",
    "output_dir = config['DEFAULT']['output_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_file_path = f'{data_home}/gutenberg/pg42324.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(local_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textimporter import TextImporter\n",
    "import langmod_funcs as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohco_pats = [\n",
    "    ('chap', r\"^(?:PREFACE|CHAPTER|LETTER)\\s\", 'm')\n",
    "]\n",
    "clip_pats = [\n",
    "    r\"^M\\. W\\. S\\.\\s*$\",\n",
    "    r\"^THE END\\.\\s*$\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "franky = TextImporter(src_file_path, ohco_pats=ohco_pats, clip_pats=clip_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing  /Users/rca2t1/Dropbox/Courses/DS/DS5001/DS5001_2024_01_R/data/gutenberg/pg42324.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^(?:PREFACE|CHAPTER|LETTER)\\s\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by delimitter [.?!;:]+\n",
      "Parsing OHCO level 3 token_num by delimitter [\\s',-]+\n"
     ]
    }
   ],
   "source": [
    "franky.import_source().parse_tokens().extract_vocab();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>_To</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Saville</td>\n",
       "      <td>saville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>_</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">82</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>10</th>\n",
       "      <td>lost</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>darkness</td>\n",
       "      <td>darkness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75721 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    token_str  term_str\n",
       "chap_id para_num sent_num token_num                    \n",
       "1       0        0        0               _To        to\n",
       "                          1               Mrs       mrs\n",
       "                 1        1           Saville   saville\n",
       "                          2           England   england\n",
       "                 2        0                 _          \n",
       "...                                       ...       ...\n",
       "28      82       1        10             lost      lost\n",
       "                          11               in        in\n",
       "                          12         darkness  darkness\n",
       "                          13              and       and\n",
       "                          14         distance  distance\n",
       "\n",
       "[75721 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franky.TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "      <th>i</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>4197</td>\n",
       "      <td>3</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>18.041696</td>\n",
       "      <td>4.173263</td>\n",
       "      <td>0.231312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>2976</td>\n",
       "      <td>3</td>\n",
       "      <td>0.039302</td>\n",
       "      <td>25.443884</td>\n",
       "      <td>4.669247</td>\n",
       "      <td>0.183512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>2852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037665</td>\n",
       "      <td>26.550140</td>\n",
       "      <td>4.730648</td>\n",
       "      <td>0.178178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>2647</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034957</td>\n",
       "      <td>28.606347</td>\n",
       "      <td>4.838263</td>\n",
       "      <td>0.169133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2101</td>\n",
       "      <td>2</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>36.040457</td>\n",
       "      <td>5.171545</td>\n",
       "      <td>0.143493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overweigh</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pledge</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salvation</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timorous</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinks</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>75721.000000</td>\n",
       "      <td>16.208406</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6965 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              n  n_chars         p             s          i         h\n",
       "term_str                                                             \n",
       "the        4197        3  0.055427     18.041696   4.173263  0.231312\n",
       "and        2976        3  0.039302     25.443884   4.669247  0.183512\n",
       "i          2852        1  0.037665     26.550140   4.730648  0.178178\n",
       "of         2647        2  0.034957     28.606347   4.838263  0.169133\n",
       "to         2101        2  0.027747     36.040457   5.171545  0.143493\n",
       "...         ...      ...       ...           ...        ...       ...\n",
       "overweigh     1        9  0.000013  75721.000000  16.208406  0.000214\n",
       "pledge        1        6  0.000013  75721.000000  16.208406  0.000214\n",
       "salvation     1        9  0.000013  75721.000000  16.208406  0.000214\n",
       "timorous      1        8  0.000013  75721.000000  16.208406  0.000214\n",
       "thinks        1        6  0.000013  75721.000000  16.208406  0.000214\n",
       "\n",
       "[6965 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franky.VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chap_id', 'para_num', 'sent_num', 'token_num']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "franky.OHCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = 3\n",
    "widx = [f\"w{i}\" for i in range(ngrams)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOV Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "franky.VOCAB['n_chars'] = franky.VOCAB.index.str.len()\n",
    "franky.VOCAB['modified_term_str'] = franky.VOCAB.index\n",
    "franky.VOCAB.loc[(franky.VOCAB.n == 1) & (franky.VOCAB.n_chars < 3), 'modified_term_str'] = \"<UNK>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "franky.TOKENS['modified_term_str'] = franky.TOKENS.term_str.map(franky.VOCAB.modified_term_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def token_to_padded(token, grouper=['sent_num'], term_str='term_str'):\n",
    "    ohco = token.index.names # We preserve these since they get lost in the shuffle\n",
    "    padded = token.groupby(grouper)\\\n",
    "        .apply(lambda x: '<s> ' + ' '.join(x[term_str]) + ' </s>')\\\n",
    "        .apply(lambda x: pd.Series(x.split()))\\\n",
    "        .stack().to_frame('term_str')\n",
    "    padded.index.names = ohco\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PADDED = token_to_padded(franky.TOKENS, grouper=franky.OHCO[:3], term_str='modified_term_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">82</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>darkness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85654 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     term_str\n",
       "chap_id para_num sent_num token_num          \n",
       "1       0        0        0               <s>\n",
       "                          1                to\n",
       "                          2               mrs\n",
       "                          3              </s>\n",
       "                 1        0               <s>\n",
       "...                                       ...\n",
       "28      82       1        11               in\n",
       "                          12         darkness\n",
       "                          13              and\n",
       "                          14         distance\n",
       "                          15             </s>\n",
       "\n",
       "[85654 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PADDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def padded_to_ngrams(padded, grouper=['sent_num'], n=2):\n",
    "    \n",
    "    ohco = padded.index.names\n",
    "    ngrams = padded.groupby(grouper)\\\n",
    "        .apply(lambda x: pd.concat([x.shift(0-i) for i in range(n)], axis=1))\\\n",
    "        .reset_index(drop=True)\n",
    "    ngrams.index = padded.index\n",
    "    ngrams.columns = widx\n",
    "    \n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NG = padded_to_ngrams(PADDED, franky.OHCO[:3], ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NG = lm.get_ngrams(franky.TOKENS, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>to</td>\n",
       "      <td>mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>mrs</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mrs</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>saville</td>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">28</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">82</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>darkness</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>darkness</td>\n",
       "      <td>and</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>distance</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85654 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           w0        w1        w2\n",
       "chap_id para_num sent_num token_num                              \n",
       "1       0        0        0               <s>        to       mrs\n",
       "                          1                to       mrs      </s>\n",
       "                          2               mrs      </s>      None\n",
       "                          3              </s>      None      None\n",
       "                 1        0               <s>   saville   england\n",
       "...                                       ...       ...       ...\n",
       "28      82       1        11               in  darkness       and\n",
       "                          12         darkness       and  distance\n",
       "                          13              and  distance      </s>\n",
       "                          14         distance      </s>      None\n",
       "                          15             </s>      None      None\n",
       "\n",
       "[85654 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# M = lm.get_ngram_counts(NG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ngrams_to_models(ngrams):\n",
    "    global widx\n",
    "    n = len(ngrams.columns)\n",
    "    model = [None for i in range(n)]\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            model[i] = ngrams.value_counts('w0').to_frame('n')\n",
    "            model[i]['p'] = model[i].n / model[i].n.sum()\n",
    "            model[i]['i'] = np.log2(1/model[i].p)\n",
    "        else:\n",
    "            model[i] = ngrams.value_counts(widx[:i+1]).to_frame('n')    \n",
    "            model[i]['cp'] = model[i].n / model[i-1].n\n",
    "            model[i]['i'] = np.log2(1/model[i].cp)\n",
    "        model[i] = model[i].sort_index()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = ngrams_to_models(NG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>cp</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11th</th>\n",
       "      <th>17</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <th>passage</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12th</th>\n",
       "      <th>17</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13th</th>\n",
       "      <th>17</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18th</th>\n",
       "      <th>17</th>\n",
       "      <th>&lt;/s&gt;</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">youthful</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">lovers</th>\n",
       "      <th>have</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>while</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">zeal</th>\n",
       "      <th>modern</th>\n",
       "      <th>philosophers</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">of</th>\n",
       "      <th>felix</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64791 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              n   cp    i\n",
       "w0       w1     w2                       \n",
       "11th     17     </s>          1  1.0  0.0\n",
       "         the    passage       1  1.0  0.0\n",
       "12th     17     </s>          1  1.0  0.0\n",
       "13th     17     </s>          1  1.0  0.0\n",
       "18th     17     </s>          2  1.0  0.0\n",
       "...                          ..  ...  ...\n",
       "youthful lovers have          1  0.5  1.0\n",
       "                while         1  0.5  1.0\n",
       "zeal     modern philosophers  1  1.0  0.0\n",
       "         of     felix         1  0.5  1.0\n",
       "                his           1  0.5  1.0\n",
       "\n",
       "[64791 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "List six words that precede the word \"monster,\" excluding stop words (and sentence boundary markers). Stop words include 'a', 'an', 'the', 'this', 'that', etc.\n",
    "\n",
    "Hint, use the `df.query()` method.\n",
    "\n",
    "**<span style=\"color:red;\">ISSUE</span>**: If you use `text_importer.py` you get a set of 6, if you parse it yourself you get 5 of the same but a different 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>cp</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>12.328114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th>monster</th>\n",
       "      <td>3</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>8.853829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abhorred</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>3.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detestable</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gigantic</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hellish</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.807355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hideous</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>3.459432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miserable</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>6.022368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <th>monster</th>\n",
       "      <td>20</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>7.713215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <th>monster</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>8.651052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n        cp          i\n",
       "w0         w1                              \n",
       "<s>        monster   1  0.000194  12.328114\n",
       "a          monster   3  0.002161   8.853829\n",
       "abhorred   monster   1  0.083333   3.584963\n",
       "detestable monster   1  0.500000   1.000000\n",
       "gigantic   monster   1  0.166667   2.584963\n",
       "hellish    monster   1  0.142857   2.807355\n",
       "hideous    monster   1  0.090909   3.459432\n",
       "miserable  monster   1  0.015385   6.022368\n",
       "the        monster  20  0.004765   7.713215\n",
       "this       monster   1  0.002488   8.651052"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[1].query(\"w1 == 'monster'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "abhorred\n",
    "detestable    \n",
    "gigantic      \n",
    "hellish       \n",
    "hideous       \n",
    "miserable     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q2 \n",
    "\n",
    "List the following sentences in ascending order of bigram perpexity according to the language model generated from the text.\n",
    "\n",
    "```\n",
    "The monster is on the ice.\n",
    "Flowers are happy things.\n",
    "I have never seen the aurora borealis.\n",
    "He never knew the love of a family.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sents = \"\"\"\n",
    "The monster is on the ice.\n",
    "Flowers are happy things.\n",
    "I have never seen the aurora borealis.\n",
    "He never knew the love of a family.\n",
    "\"\"\".split('\\n')[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence_to_token(sent_list, file=True):\n",
    "    \n",
    "    # Convert list of sentences to dataframe\n",
    "    if file:\n",
    "        S = pd.read_csv(\"test_sentences.txt\", header=None, names=['sent_str'])\n",
    "    else:\n",
    "        S = pd.DataFrame(sent_list, columns=['sent_str'])\n",
    "    S.index.name = 'sent_num'\n",
    "    \n",
    "    # Convert dataframe of sentences to TOKEN with normalized terms\n",
    "    K = S.sent_str.apply(lambda x: pd.Series(x.split())).stack().to_frame('token_str')\n",
    "    K['term_str'] = K.token_str.str.replace(r\"[\\W_]+\", \"\", regex=True).str.lower()\n",
    "    K.index.names = ['sent_num', 'token_num']\n",
    "    \n",
    "    return S, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_SENTS, TEST_TOKENS = sentence_to_token(test_sents, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_PADDED = token_to_padded(TEST_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_NGRAMS = padded_to_ngrams(TEST_PADDED, n=ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(model, ngrams):\n",
    "    \n",
    "    global widx\n",
    "    \n",
    "    assert len(model) == len(ngrams.columns)\n",
    "    \n",
    "    n = len(model)\n",
    "    ohco = ngrams.index.names\n",
    "    \n",
    "    R = []\n",
    "    for i in range(n):\n",
    "        T = ngrams.merge(M[i], on=widx[:i+1], how='left')\n",
    "        T.index = ngrams.index\n",
    "        T = T.reset_index().set_index(ohco + widx).i #.to_frame(f\"i{i}\")\n",
    "        \n",
    "        # This how we handle unseen combos\n",
    "        T[T.isna()] = T.max()\n",
    "        R.append(T.to_frame(f\"i{i}\"))\n",
    "                \n",
    "    return pd.concat(R, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "R = test_model(M, TEST_NGRAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>i0</th>\n",
       "      <th>i1</th>\n",
       "      <th>i2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>the</th>\n",
       "      <th>monster</th>\n",
       "      <td>4.058119</td>\n",
       "      <td>3.816361</td>\n",
       "      <td>7.511753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>the</th>\n",
       "      <th>monster</th>\n",
       "      <th>is</th>\n",
       "      <td>4.351090</td>\n",
       "      <td>7.713215</td>\n",
       "      <td>7.511753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>monster</th>\n",
       "      <th>is</th>\n",
       "      <th>on</th>\n",
       "      <td>11.432037</td>\n",
       "      <td>10.438792</td>\n",
       "      <td>7.511753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>is</th>\n",
       "      <th>on</th>\n",
       "      <th>the</th>\n",
       "      <td>8.124138</td>\n",
       "      <td>6.262095</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>on</th>\n",
       "      <th>the</th>\n",
       "      <th>ice</th>\n",
       "      <td>7.543883</td>\n",
       "      <td>1.623182</td>\n",
       "      <td>7.219169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   i0         i1        i2\n",
       "sent_num token_num w0      w1      w2                                     \n",
       "0        0         <s>     the     monster   4.058119   3.816361  7.511753\n",
       "         1         the     monster is        4.351090   7.713215  7.511753\n",
       "         2         monster is      on       11.432037  10.438792  7.511753\n",
       "         3         is      on      the       8.124138   6.262095  2.000000\n",
       "         4         on      the     ice       7.543883   1.623182  7.219169"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_perplexity(results, test_sents, n=3):\n",
    "    for i in range(n):\n",
    "        test_sents[f\"pp{i}\"] = np.exp2(results.groupby('sent_num')[f\"i{i}\"].mean())\n",
    "    return test_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PP = compute_perplexity(R, TEST_SENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "      <th>pp0</th>\n",
       "      <th>pp1</th>\n",
       "      <th>pp2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The monster is on the ice.</td>\n",
       "      <td>116.146797</td>\n",
       "      <td>80.632951</td>\n",
       "      <td>68.983256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He never knew the love of a family.</td>\n",
       "      <td>170.855904</td>\n",
       "      <td>136.870520</td>\n",
       "      <td>64.734928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have never seen the aurora borealis.</td>\n",
       "      <td>340.954187</td>\n",
       "      <td>138.718691</td>\n",
       "      <td>81.279212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers are happy things.</td>\n",
       "      <td>587.205060</td>\n",
       "      <td>533.982028</td>\n",
       "      <td>182.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sent_str         pp0         pp1  \\\n",
       "sent_num                                                                   \n",
       "0                     The monster is on the ice.  116.146797   80.632951   \n",
       "3            He never knew the love of a family.  170.855904  136.870520   \n",
       "2         I have never seen the aurora borealis.  340.954187  138.718691   \n",
       "1                      Flowers are happy things.  587.205060  533.982028   \n",
       "\n",
       "                 pp2  \n",
       "sent_num              \n",
       "0          68.983256  \n",
       "3          64.734928  \n",
       "2          81.279212  \n",
       "1         182.500000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP.sort_values('pp1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 0, 3, 2, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "Using the bigram model represented as a matrix, explore the relationship between bigram pairs as done in the \"Explore\" section of the template notebook, but use the following lists. **What might you speculate about gender and communication given the results you see?**\n",
    "* `['he','she']` to select the indices.\n",
    "* `['said','heard']` to select the columns.\n",
    "\n",
    "Hint: use `.unstack()` method on the feature `n` and then use `.loc[]` to select the first list from the index, and the second list from the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BGX = M[1].n.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1   said  heard\n",
      "w0              \n",
      "he   21.0    5.0\n",
      "she   3.0    3.0\n"
     ]
    }
   ],
   "source": [
    "print(BGX.loc[['he','she'],['said','heard']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speculation: Men talk more than women."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Generate a text using the `generate_text` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(M, n=250):\n",
    "    \n",
    "    if len(M) < 3:\n",
    "        raise ValueError(\"Must have trigram model generated.\")\n",
    "    \n",
    "    # Start list of words\n",
    "    first_word = M[1].loc['<s>'].sample(weights='cp').index[0]\n",
    "    \n",
    "    words = ['<s>', first_word]\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        bg = tuple(words[-2:])\n",
    "\n",
    "        # Try trigram model\n",
    "        try:\n",
    "            next_word = M[2].loc[bg].sample(weights='cp').index[0]\n",
    "\n",
    "        # If not found in model, back off ...\n",
    "        except KeyError as e1:\n",
    "            try:\n",
    "                # Get the last word in the bigram\n",
    "                ug = bg[1]\n",
    "                next_word = M[1].loc[ug].sample(weights='cp').index[0]\n",
    "            \n",
    "            except KeyError as e2:\n",
    "                next_word = M[0].sample(weights='p').index[0]\n",
    "                \n",
    "        words.append(next_word)\n",
    "    \n",
    "    \n",
    "    text = ' '.join(words[2:])\n",
    "    print('\\n\\n'.join([str(i+1) + ' ' + line.replace('<s>','')\\\n",
    "        .strip().upper() for i, line in enumerate(text.split('</s>'))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 WHOLE OF THE WRETCHED SPHERE OF MY ENEMY AND UNPROTECTED TO THE COURT WAS HELD\n",
      "\n",
      "2 MY PLAN OF YOUR HANDS\n",
      "\n",
      "3 ALMOST AS IMPOSING AND INTERESTING AS TRUTH\n",
      "\n",
      "4 ARDENTLY HOPE THAT YOUR OTHER DUTIES ARE EQUALLY NEGLECTED\n",
      "\n",
      "5 I SLAKED MY THIRST FOR SYMPATHY AND COMPASSION CONFIRMED MY RESOLUTION TO PURSUE MY DESTROYER IN ITS GENERAL RELATIONS AND THAT CLERVAL SHOULD JOIN ME AT ONCE WITH FRIGHTFUL LOUDNESS FROM VARIOUS QUARTERS OF THE NEARLY PERPENDICULAR ASCENT OF MONT SALÊVE\n",
      "\n",
      "6 AND THUS WHILE THEY EXIST YOU SHALL CURSE THE HOUR FROM WHICH THE MURDER HAD DISCOVERED IN HER HIDING PLACES\n",
      "\n",
      "7 THE IDEA OF THE ACCUSED\n",
      "\n",
      "8 OF COLD AND WET AT LENGTH EXHAUSTED BY HIS PRESENCE BROUGHT BACK DESPAIR TO HIM TO BE MEN ON WHOM I HAD SO MISERABLY\n",
      "\n",
      "9 DEAR SISTER BUT I WAS SEATED IN A LOUD SCREAM I FIRED THE STRAW AND FELL AT HIS FEET\n",
      "\n",
      "10 CLEAR CONCEPTION OF MY LABOURS DID NOT SATISFY MY OWN VAMPIRE MY OWN INEXPERIENCE AND MISTAKE THAN TO THE COUNTY TOWN WHERE THE MERCHANT HAD DECIDED TO WAIT A FAVOURABLE OPPORTUNITY OF PASSING INTO SOME PART OF THE PRECEDING FLASH\n",
      "\n",
      "11 THE FIEND WHOM I HAD INHABITED ABOUT THE END OF JULY\n",
      "\n",
      "12 THE BALLOTS HAD BEEN FILLED UP WITH INDIGNATION NOW SUBDUED TO DOWNCAST SORROW AND QUENCHED IN INFINITE WRETCHEDNESS\n",
      "\n",
      "13 DISCOVERED THE NAMES OF THE MEN BROUGHT ME AND I SAW THE FISH PLAY IN THE SICKNESS OF FEAR\n",
      "\n",
      "14 MURDER HAD BEEN AN\n"
     ]
    }
   ],
   "source": [
    "generate_text(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q5\n",
    "\n",
    "Compute the redundancy $R$ for each of the n-gram models using the MLE of the joint probability of each ngram type. In other words, for each model, just use the `.mle` feature as $p$ in computing $H = \\sum p(ng) \\log_2(1/p(ng))$\n",
    "\n",
    "Remember that $R = 1 - \\frac{H}{H_{max}}$, where $H$ is the actual entropy of the model and $H_{max}$ is its maximum entropy. \n",
    "\n",
    "Does $R$ increase, decrease, or remain the same as the choice of n-gram increases in length?\n",
    "\n",
    "**Hints**:\n",
    "- If `mle` is not a feature in your models, just use `p` for the unigram model and compute `p` for the other two models by dividing `n` by the sum of `n`, i.e. \n",
    "\n",
    "```python\n",
    "M[1]['p'] = M[1].n /  M[1].n.sum()\n",
    "M[2]['p'] = M[2].n /  M[2].n.sum()\n",
    "```\n",
    "- N is computed as the number of all possible combinations for each ngram. So, for the bigram model N is the number of unigrams (i.e. the vocabulary size plus the sentence boundary signs) squared, and for the trigram model the value is cubed, i.e.\n",
    "\n",
    "```python\n",
    "N = len(M[0].index)**{i+1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "V = len(M[0].index)\n",
    "\n",
    "M[1]['p'] = M[1].n /  M[1].n.sum()\n",
    "M[2]['p'] = M[2].n /  M[2].n.sum()\n",
    "\n",
    "R = []\n",
    "for i in range(3):\n",
    "    N = V**(i+1)\n",
    "    H = (M[i].p * np.log2(1/M[i].p)).sum()\n",
    "    Hmax = np.log2(N)\n",
    "    print(i, N, Hmax)\n",
    "    R.append(int(round(1 - H/Hmax, 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31, 45, 59]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: Redundancy increases."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS5559_LMs.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235.517px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
